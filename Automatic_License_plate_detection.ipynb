{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlY1B3U39aSR/442IJ6mdN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KashishOswal9/Automatic-License-plate-detection/blob/main/Automatic_License_plate_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "id": "3JRQECsWdMZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ABfst09NIvE9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import easyocr\n",
        "import imutils\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reorder points for perspective transform\n",
        "def order_points(pts):\n",
        "    pts = pts.reshape(4, 2)\n",
        "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
        "    s = pts.sum(axis=1)\n",
        "    rect[0] = pts[np.argmin(s)]  # top-left\n",
        "    rect[2] = pts[np.argmax(s)]  # bottom-right\n",
        "    diff = np.diff(pts, axis=1)\n",
        "    rect[1] = pts[np.argmin(diff)]  # top-right\n",
        "    rect[3] = pts[np.argmax(diff)]  # bottom-left\n",
        "    return rect\n",
        "\n",
        "def four_point_transform(image, pts):\n",
        "    rect = order_points(pts)\n",
        "    (tl, tr, br, bl) = rect\n",
        "    widthA = np.linalg.norm(br - bl)\n",
        "    widthB = np.linalg.norm(tr - tl)\n",
        "    maxWidth = max(int(widthA), int(widthB))\n",
        "    heightA = np.linalg.norm(tr - br)\n",
        "    heightB = np.linalg.norm(tl - bl)\n",
        "    maxHeight = max(int(heightA), int(heightB))\n",
        "    dst = np.array([[0, 0], [maxWidth - 1, 0],\n",
        "                    [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]], dtype=\"float32\")\n",
        "    M = cv2.getPerspectiveTransform(rect, dst)\n",
        "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
        "    return warped\n",
        "\n",
        "def preprocess_plate(plate_img):\n",
        "    gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)\n",
        "    kernel = np.array([[0, -1, 0], [-1, 5,-1], [0, -1, 0]])\n",
        "    sharp = cv2.filter2D(gray, -1, kernel)\n",
        "    thresh = cv2.adaptiveThreshold(sharp, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                   cv2.THRESH_BINARY, 25, 15)\n",
        "    return thresh\n",
        "\n"
      ],
      "metadata": {
        "id": "vEvIisvVJ-qW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_and_read_plates(frame, reader):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    bfilter = cv2.bilateralFilter(gray, 11, 17, 17)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
        "    morph = cv2.morphologyEx(bfilter, cv2.MORPH_CLOSE, kernel)\n",
        "    edged = cv2.Canny(morph, 30, 200)\n",
        "\n",
        "    contours = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = imutils.grab_contours(contours)\n",
        "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:100]\n",
        "\n",
        "    plates = []\n",
        "    for contour in contours:\n",
        "        peri = cv2.arcLength(contour, True)\n",
        "        approx = cv2.approxPolyDP(contour, 0.018 * peri, True)\n",
        "        if len(approx) == 4:\n",
        "            (x, y, w, h) = cv2.boundingRect(approx)\n",
        "            aspect_ratio = w / float(h)\n",
        "            area = cv2.contourArea(approx)\n",
        "            if 2 < aspect_ratio < 6 and area > 1200:\n",
        "                warped = four_point_transform(frame, approx)\n",
        "                preprocessed = preprocess_plate(warped)\n",
        "                results = reader.readtext(preprocessed)\n",
        "                if results:\n",
        "                    best_text = max(results, key=lambda r: r[2])\n",
        "                    text = best_text[1]\n",
        "                    confidence = best_text[2]\n",
        "                    plates.append((text, confidence, approx))\n",
        "    return plates\n",
        "\n",
        "def draw_plates(frame, plates):\n",
        "    for (text, conf, approx) in plates:\n",
        "        pts = approx.reshape(4, 2)\n",
        "\n",
        "        # Draw rectangle on plate\n",
        "        for i in range(4):\n",
        "            pt1 = tuple(pts[i])\n",
        "            pt2 = tuple(pts[(i+1) % 4])\n",
        "            cv2.line(frame, pt1, pt2, (0, 255, 0), 2)\n",
        "\n",
        "        # Calculate center-bottom location for text\n",
        "        min_y = np.max(pts[:,1]) + 40  # below plate\n",
        "        min_x = int(np.mean(pts[:,0])) - 100  # center roughly\n",
        "        label = f\"{text}\"\n",
        "\n",
        "        # Draw large readable text below the car\n",
        "        cv2.putText(frame, label, (min_x, min_y), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    return frame\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def process_single_image(image_path, reader):\n",
        "    img = cv2.imread(image_path)\n",
        "    plates = detect_and_read_plates(img, reader)\n",
        "\n",
        "    # Filter to keep only the most confident plate (if multiple)\n",
        "    if plates:\n",
        "        # Sort by confidence, keep only the best one\n",
        "        plates = [max(plates, key=lambda x: x[1])]\n",
        "\n",
        "    result = draw_plates(img, plates)\n",
        "    cv2_imshow(result)  # Show in Colab\n",
        "    cv2.imwrite(\"output_image.jpg\", result)\n",
        "\n",
        "\n",
        "def process_video(video_path, reader):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"❌ Cannot open video file: {video_path}\")\n",
        "        return\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = None\n",
        "    frame_width = int(cap.get(3))\n",
        "    frame_height = int(cap.get(4))\n",
        "\n",
        "    out = cv2.VideoWriter('output_video.mp4', fourcc, 20.0, (frame_width, frame_height))\n",
        "\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        plates = detect_and_read_plates(frame, reader)\n",
        "        output_frame = draw_plates(frame.copy(), plates)\n",
        "        out.write(output_frame)\n",
        "        frame_count += 1\n",
        "        if frame_count % 30 == 0:\n",
        "            print(f\"Processed {frame_count} frames...\")\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(\"✅ Video processing done. Saved as output_video.mp4\")\n"
      ],
      "metadata": {
        "id": "rrVDsMcrKB8j"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    reader = easyocr.Reader(['en'])\n",
        "\n",
        "    # Step 1️⃣ Image Output\n",
        "    process_single_image('image1.jpg', reader)\n",
        "\n",
        "    # Step 2️⃣ Video Output\n",
        "    process_video('car1.mp4', reader)\n",
        "\n",
        "main()\n",
        "\n"
      ],
      "metadata": {
        "id": "BK_wMzynKDTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"output_video.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TkQbeHETKLQk",
        "outputId": "815a09f6-916d-4569-c3e9-9777f99aee91"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_685d741f-a7a7-440d-9da4-1a10952969a5\", \"output_video.mp4\", 6607024)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}